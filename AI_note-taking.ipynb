{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Smart Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "def get_groq_mistral_response(prompt: str) -> str:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"mistral-saba-24b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_completion_tokens=1024,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,    \n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Groq Error: {e}\")\n",
    "        return \"‚ö†Ô∏è Error from Groq/Mistral API.\"\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_highlight_prompt(text: str) -> str:\n",
    "    return f\"\"\"\n",
    "    You are an advanced document annotator with expertise in analyzing and classifying highlighted text. Your task is to provide a **precise and insightful annotation** for the given highlight.\n",
    "\n",
    "    1. **Classify the Highlight Type**:  \n",
    "       Choose from the following categories:\n",
    "       - **Concept** (A single idea, definition, or principle)  \n",
    "       - **Process** (Step-by-step explanation or structured reasoning)  \n",
    "       - **Fact** (A verified statement, research finding, or statistic)  \n",
    "       - **Task** (A to-do item or action-based instruction)  \n",
    "       - **Formula** (A structured or mathematical representation)  \n",
    "\n",
    "    2. **Classify the Sentence Type** (Choose the best match):  \n",
    "       - **Definition**  \n",
    "       - **Explanation**  \n",
    "       - **Quote**  \n",
    "       - **Important Fact**  \n",
    "       - **Recommendation**  \n",
    "       - **Author's Opinion**  \n",
    "       - **Analogy**  \n",
    "       - **Other (Specify if needed)**  \n",
    "\n",
    "    3. **Generate a Short Note**:  \n",
    "       - Clearly **explain the significance** of the highlight in 1-2 sentences.  \n",
    "       - Avoid generic phrases like \"This sentence describes...\"  \n",
    "       - Use **engaging and direct** phrasing: \"It highlights...\", \"It defines...\", \"It recommends...\".  \n",
    "\n",
    "    **Highlighted Sentence:**  \n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "    **Respond ONLY in this format (no extra text):**  \n",
    "    - **Highlight Type**: [One of Concept, Process, Fact, Task, Formula]  \n",
    "    - **Sentence Type**: [One of Definition, Explanation, Quote, etc.]  \n",
    "    - **Short Note**: [A brief, professional annotation]  \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# def smart_highlight_prompt(text: str) -> str:\n",
    "#    return f\"\"\"\n",
    "#    You are an advanced document annotator with expertise in analyzing and classifying highlighted sentences. Your task is to provide a professional and insightful annotation for the given highlighted sentence. Follow these steps:\n",
    "\n",
    "#    1. **Classify the Highlight**: Determine whether the highlighted text is a \"Concept\" (a concise idea or definition) or a \"Paragraph\" (a more detailed explanation or narrative). \n",
    "#       - If the highlighted text is a \"Concept\" (e.g., \"Deep Learning\"), provide a short and precise definition or explanation.\n",
    "#       - If the highlighted text is a \"Paragraph\", generate a concise TL;DR summary that captures the essence of the content.\n",
    "\n",
    "#    2. **Classify the Sentence**: Determine the type of the highlighted sentence from the following categories:\n",
    "#       - Summary\n",
    "#       - Definition\n",
    "#       - Explanation\n",
    "#       - Quote\n",
    "#       - Important Fact\n",
    "#       - Recommendation\n",
    "#       - Author's Opinion\n",
    "#       - Analogy\n",
    "#       - Other (specify if none of the above)\n",
    "\n",
    "#    3. **Provide a Short Note**: Write a concise and user-friendly annotation that explains the essence of the highlighted sentence. Avoid generic phrases like \"This sentence describes...\". Instead, use direct and meaningful language such as \"It highlights...\", \"It defines...\", or \"It recommends...\".\n",
    "\n",
    "#    4. **Ensure Clarity and Precision**: Your response should be clear, precise, and helpful to the user. Avoid overly complex language or unnecessary elaboration.\n",
    "\n",
    "#    Highlighted Sentence:\n",
    "#    \\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "#    Respond with:\n",
    "#    - **Highlight Type**: (Concept or Paragraph)\n",
    "#    - **Sentence Type**: (e.g., Explanation, Quote)\n",
    "#    - **Short Note**: (A one-sentence annotation that captures the essence of the highlighted sentence in a professional and insightful manner)\n",
    "\n",
    "#    Make your response polished, accurate, and user-friendly.\n",
    "#    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Highlight Type**: Concept\n",
      "- **Sentence Type**: Definition\n",
      "- **Short Note**: It defines reinforcement learning as a method that uses reward feedback to train agents on performing tasks.\n"
     ]
    }
   ],
   "source": [
    "# Concept\n",
    "highlight1 = \"Reinforcement learning uses reward feedback to teach agents how to act.\"\n",
    "prompt = smart_highlight_prompt(highlight1)\n",
    "print(get_groq_mistral_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Highlight Type**: Concept\n",
      "- **Sentence Type**: Explanation\n",
      "- **Short Note**: It highlights the trade-offs and efficiency considerations between float16 and bfloat16 compared to float32 for representing numerical values, especially in the context of GPU performance during matrix multiplications.\n"
     ]
    }
   ],
   "source": [
    "# For paragraph\n",
    "highlight2 = \"Float16 can only represent numbers up to 65504, whilst bfloat16 can represent huge numbers up to 10^38! But notice both number formats use only 16bits! This is because float16 allocates more bits so it can represent smaller decimals better, whilst bfloat16 cannot represent fractions well. But why float16? Let's just use float32! But unfortunately float32 in GPUs is very slow for matrix multiplications - sometimes 4 to 10x slower! So we cannot do this.\"\n",
    "\n",
    "prompt = smart_highlight_prompt(highlight2)\n",
    "print(get_groq_mistral_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Semantic summary prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_summary_prompt(highlights: list) -> str:\n",
    "  return f\"\"\"\n",
    "    You are an AI-powered summarization expert. Your task is to analyze the provided highlights and generate a **concise study memory** in a well-structured, high-impact paragraph.\n",
    "\n",
    "    ### **Instructions:**\n",
    "    1. **Capture the key insights** from the highlights without repeating information.  \n",
    "    2. **Group related ideas** for a logical flow (e.g., learning techniques, AI advancements, safety concerns).  \n",
    "    3. **Make it clear, precise, and engaging**, avoiding unnecessary filler words.  \n",
    "    4. **Ensure natural readability** ‚Äì the summary should feel polished and professional.\n",
    "\n",
    "    ### **Highlights to Summarize:**  \n",
    "    {highlights}\n",
    "\n",
    "    ### **Respond in the following format:**  \n",
    "    - **Compressed Study Memory:**  \n",
    "      - [A single, structured paragraph summarizing the highlights effectively]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Compressed Study Memory:**\n",
      "  Machine learning encompasses various techniques including backpropagation, which trains neural networks through error feedback and weight adjustments, and reinforcement learning, where models learn by receiving rewards or penalties. Activation functions determine neuron activation in neural networks, while gradient descent optimizes model parameters. Deep learning, surpassing human capabilities in perceptual tasks, involves deep neural networks with multiple hidden layers. Ensuring model generalizability requires dropout regularization to prevent overfitting, and combining transfer learning with fine-tuning on domain-specific datasets enhances performance. Notable milestones include OpenAI's ChatGPT hitting 100 million users in two months, highlighting AI's rapid growth. Safety remains a pressing concern; Elon Musk emphasizes stringent regulation to mitigate potential catastrophic risks.\n"
     ]
    }
   ],
   "source": [
    "highlight1 = \"Backpropagation is a supervised learning algorithm used to train neural networks by adjusting weights based on error feedback.\"\n",
    "highlight2 = \"The activation function in a neural network determines whether a neuron should be activated based on weighted inputs.\"\n",
    "highlight3 = \"Reinforcement learning allows an agent to learn by receiving rewards or penalties, optimizing future decisions based on past actions.\" \n",
    "highlight4 = \"Gradient descent is an optimization algorithm that adjusts model parameters by computing the gradient of the loss function.\"\n",
    "highlight5 = \"As Geoffrey Hinton once said, 'Deep learning is the first technology in history that can solve perceptual problems better than humans.'\"\n",
    "highlight6 = \"Elon Musk argues that AI safety is humanity‚Äôs biggest challenge, requiring careful regulation to prevent catastrophic outcomes.\" \n",
    "highlight7 = \"Neural networks with more than three hidden layers are commonly referred to as deep neural networks.\"\n",
    "highlight8 = \"In 2023, OpenAI's ChatGPT reached 100 million users within just two months, making it the fastest-growing app in history.\"\n",
    "highlight9 = \"To improve model generalization, always use dropout regularization to prevent overfitting in deep learning models.\"\n",
    "highlight10 = \"For high-performance AI models, use a combination of transfer learning and fine-tuning on domain-specific datasets.\"\n",
    "\n",
    "highlights = [highlight1, highlight2, highlight3, highlight4, highlight5, highlight6, highlight7, highlight8, highlight9, highlight10]\n",
    "prompt = semantic_summary_prompt(highlights)\n",
    "print(get_groq_mistral_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ML based Auto-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/miniforge3/envs/NCvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ **Note:** Backpropagation is used in neural networks.\n",
      "üìå **Detected Entities:** []\n",
      "\n",
      "üîπ **Note:** Here‚Äôs a cool formula I found: E = mc¬≤.\n",
      "üìå **Detected Entities:** []\n",
      "\n",
      "üîπ **Note:** Important deadline: Submit research paper by Friday.\n",
      "üìå **Detected Entities:** [('Friday', 'DATE')]\n",
      "\n",
      "üîπ **Note:** In 2023, OpenAI‚Äôs ChatGPT became the fastest-growing app in history.\n",
      "üìå **Detected Entities:** [('2023', 'DATE'), ('OpenAI', 'ORG'), ('ChatGPT', 'PRODUCT')]\n",
      "\n",
      "üîπ **Note:** The sigmoid activation function is used in logistic regression.\n",
      "üìå **Detected Entities:** []\n",
      "\n",
      "üîπ **Note:** Elon Musk warns about the risks of AI surpassing human intelligence.\n",
      "üìå **Detected Entities:** [('Elon Musk', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load a more powerful transformer-based model\n",
    "nlp = spacy.load(\"en_core_web_trf\")  # More accurate than \"en_core_web_sm\"\n",
    "\n",
    "# Sample notes\n",
    "notes = [\n",
    "    \"Backpropagation is used in neural networks.\",\n",
    "    \"Here‚Äôs a cool formula I found: E = mc¬≤.\",\n",
    "    \"Important deadline: Submit research paper by Friday.\",\n",
    "    \"In 2023, OpenAI‚Äôs ChatGPT became the fastest-growing app in history.\",\n",
    "    \"The sigmoid activation function is used in logistic regression.\",\n",
    "    \"Elon Musk warns about the risks of AI surpassing human intelligence.\"\n",
    "]\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities using a transformer-based model.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Process each note\n",
    "for note in notes:\n",
    "    print(f\"\\nüîπ **Note:** {note}\")\n",
    "    print(\"üìå **Detected Entities:**\", extract_entities(note))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/miniforge3/envs/NCvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0_complex_networks_neural_and</td>\n",
       "      <td>[complex, networks, neural, and, is, are, deep...</td>\n",
       "      <td>[quantum physics is fascinating and complex., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1_data_ai_with_is</td>\n",
       "      <td>[data, ai, with, is, improve, discuss, model, ...</td>\n",
       "      <td>[python is widely used for data science., data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2_the_meeting_pm_at</td>\n",
       "      <td>[the, meeting, pm, at, with, dr, friday, proje...</td>\n",
       "      <td>[the deadline for the project is next monday.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3_mc¬≤_formulated_motion_mass</td>\n",
       "      <td>[mc¬≤, formulated, motion, mass, of, relationsh...</td>\n",
       "      <td>[einstein's equation: e=mc¬≤., e=mc¬≤ describes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0      0      5  0_complex_networks_neural_and   \n",
       "1      1      5              1_data_ai_with_is   \n",
       "2      2      4            2_the_meeting_pm_at   \n",
       "3      3      3   3_mc¬≤_formulated_motion_mass   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [complex, networks, neural, and, is, are, deep...   \n",
       "1  [data, ai, with, is, improve, discuss, model, ...   \n",
       "2  [the, meeting, pm, at, with, dr, friday, proje...   \n",
       "3  [mc¬≤, formulated, motion, mass, of, relationsh...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [quantum physics is fascinating and complex., ...  \n",
       "1  [python is widely used for data science., data...  \n",
       "2  [the deadline for the project is next monday.,...  \n",
       "3  [einstein's equation: e=mc¬≤., e=mc¬≤ describes ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap.umap_ import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Preprocess the text (e.g., lowercasing, removing stopwords, etc.)\n",
    "def preprocess_text(docs):\n",
    "    return [doc.lower() for doc in docs]\n",
    "\n",
    "docs = [\n",
    "    \"Backpropagation is used in neural networks.\",\n",
    "    \"Submit the report by Friday.\",\n",
    "    \"Einstein's equation: E=mc¬≤.\",\n",
    "    \"Meeting with Dr. Smith at 3 PM.\",\n",
    "    \"Neural networks can learn complex patterns.\",\n",
    "    \"Activation functions like ReLU and Sigmoid are crucial.\",\n",
    "    \"Machine learning models improve with more data.\",\n",
    "    \"Quantum physics is fascinating and complex.\",\n",
    "    \"Newton formulated the laws of motion.\",\n",
    "    \"The deadline for the project is next Monday.\",\n",
    "    \"Discuss the new AI model with the team.\",\n",
    "    \"A research paper on AI ethics was published.\",\n",
    "    \"Data preprocessing is a key step in ML pipelines.\",\n",
    "    \"Professor John teaches deep learning at MIT.\",\n",
    "    \"Python is widely used for data science.\",\n",
    "    \"E=mc¬≤ describes the relationship between energy and mass.\",\n",
    "    \"Meeting scheduled at 2 PM with the research team.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Preprocess the documents\n",
    "processed_docs = preprocess_text(docs)\n",
    "\n",
    "# Use a custom embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Fine-tune UMAP settings\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, metric=\"cosine\", random_state=42)\n",
    "\n",
    "# Fine-tune HDBSCAN settings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=2, min_samples=1, metric=\"euclidean\", cluster_selection_method=\"eom\")\n",
    "\n",
    "# Initialize BERTopic with custom models\n",
    "topic_model = BERTopic(embedding_model=embedding_model, umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "\n",
    "# Fit and transform the documents\n",
    "topics, probs = topic_model.fit_transform(processed_docs)\n",
    "\n",
    "# Print the topics and their keywords\n",
    "topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå 'Backpropagation is used in neural networks.' ‚Üí Tag: #complex, networks, neural, and, is, are, deep, fascinating, functions, crucial\n",
      "üìå 'Submit the report by Friday.' ‚Üí Tag: #the, meeting, pm, at, with, dr, friday, project, monday, next\n",
      "üìå 'Einstein's equation: E=mc¬≤.' ‚Üí Tag: #mc¬≤, formulated, motion, mass, of, relationship, einstein, laws, describes, equation\n",
      "üìå 'Meeting with Dr. Smith at 3 PM.' ‚Üí Tag: #the, meeting, pm, at, with, dr, friday, project, monday, next\n",
      "üìå 'Neural networks can learn complex patterns.' ‚Üí Tag: #complex, networks, neural, and, is, are, deep, fascinating, functions, crucial\n",
      "üìå 'Activation functions like ReLU and Sigmoid are crucial.' ‚Üí Tag: #complex, networks, neural, and, is, are, deep, fascinating, functions, crucial\n",
      "üìå 'Machine learning models improve with more data.' ‚Üí Tag: #data, ai, with, is, improve, discuss, model, key, ml, machine\n",
      "üìå 'Quantum physics is fascinating and complex.' ‚Üí Tag: #complex, networks, neural, and, is, are, deep, fascinating, functions, crucial\n",
      "üìå 'Newton formulated the laws of motion.' ‚Üí Tag: #mc¬≤, formulated, motion, mass, of, relationship, einstein, laws, describes, equation\n",
      "üìå 'The deadline for the project is next Monday.' ‚Üí Tag: #the, meeting, pm, at, with, dr, friday, project, monday, next\n",
      "üìå 'Discuss the new AI model with the team.' ‚Üí Tag: #data, ai, with, is, improve, discuss, model, key, ml, machine\n",
      "üìå 'A research paper on AI ethics was published.' ‚Üí Tag: #data, ai, with, is, improve, discuss, model, key, ml, machine\n",
      "üìå 'Data preprocessing is a key step in ML pipelines.' ‚Üí Tag: #data, ai, with, is, improve, discuss, model, key, ml, machine\n",
      "üìå 'Professor John teaches deep learning at MIT.' ‚Üí Tag: #complex, networks, neural, and, is, are, deep, fascinating, functions, crucial\n",
      "üìå 'Python is widely used for data science.' ‚Üí Tag: #data, ai, with, is, improve, discuss, model, key, ml, machine\n",
      "üìå 'E=mc¬≤ describes the relationship between energy and mass.' ‚Üí Tag: #mc¬≤, formulated, motion, mass, of, relationship, einstein, laws, describes, equation\n",
      "üìå 'Meeting scheduled at 2 PM with the research team.' ‚Üí Tag: #the, meeting, pm, at, with, dr, friday, project, monday, next\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    topic_name = topic_model.get_topic(topics[i])\n",
    "    topic_keywords = \", \".join([word for word, _ in topic_name]) if topic_name else \"No Topic\"\n",
    "    print(f\"üìå '{doc}' ‚Üí Tag: #{topic_keywords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-generated tags: {'PERSON': ['Elon Musk'], 'ORG': ['SpaceX'], 'GPE': ['Hawthorne'], 'DATE': ['2024-03-15'], 'LOC': ['Mars']}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's pre-trained NER model\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Sample note\n",
    "text = \"Meeting with Elon Musk at SpaceX HQ in Hawthorne on 2024-03-15. Discussed Mars colonization timelines.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract entities\n",
    "tags = {ent.label_: [] for ent in doc.ents}\n",
    "for ent in doc.ents:\n",
    "    tags[ent.label_].append(ent.text)\n",
    "\n",
    "print(\"Auto-generated tags:\", tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-generated tags: {}\n"
     ]
    }
   ],
   "source": [
    "# Auto-generated tags: {'PERSON': ['Elon Musk'], 'ORG': ['SpaceX'], 'GPE': ['Hawthorne'], 'DATE': ['2024-03-15'], 'LOC': ['Mars']}\n",
    "text = \"Backpropagation is used in neural networks.\"\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "doc = nlp(text)\n",
    "tags = {ent.label_: [] for ent in doc.ents}\n",
    "for ent in doc.ents:\n",
    "    tags[ent.label_].append(ent.text)\n",
    "\n",
    "print(\"Auto-generated tags:\", tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Final Cleaned Auto-Generated Tags:\n",
      "- Google\n",
      "- Nasa\n",
      "- New Quantum Computing Chip\n",
      "- Quantum Computing\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from rake_nltk import Rake\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Initialize tools\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "rake = Rake()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"Google is developing a new quantum computing chip in collaboration with NASA.\"\n",
    "\n",
    "# ---------- Step 1: NER ----------\n",
    "doc = nlp(sentence)\n",
    "ner_tags = list(set(ent.text for ent in doc.ents))\n",
    "\n",
    "# ---------- Step 2: Keyword Extraction ----------\n",
    "rake.extract_keywords_from_text(sentence)\n",
    "rake_tags = rake.get_ranked_phrases()\n",
    "\n",
    "# ---------- Step 3: Semantic Tag Matching ----------\n",
    "# Predefined tag candidates (can be domain-specific or broad)\n",
    "candidate_tags = [\n",
    "    \"Quantum Computing\", \"AI\", \"Google\", \"NASA\", \"Technology\", \"Hardware\",\n",
    "    \"Space\", \"Machine Learning\", \"Semiconductor\", \"Research\", \"Partnership\"\n",
    "]\n",
    "\n",
    "# Encode sentence and candidate tags\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "tag_embeddings = model.encode(candidate_tags, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarities\n",
    "cosine_scores = util.cos_sim(sentence_embedding, tag_embeddings)[0]\n",
    "\n",
    "# Threshold filtering (tweak as needed)\n",
    "semantic_tags = [\n",
    "    candidate_tags[i]\n",
    "    for i in range(len(candidate_tags))\n",
    "    if cosine_scores[i] > 0.45  # threshold for semantic match\n",
    "]\n",
    "\n",
    "# ---------- Combine All ----------\n",
    "# all_tags = list(set(ner_tags + rake_tags + semantic_tags))\n",
    "\n",
    "# print(\"üìå Final Auto-Generated Tags:\")\n",
    "# for tag in all_tags:\n",
    "#     print(\"-\", tag)\n",
    "\n",
    "# Combine all tags and normalize\n",
    "raw_tags = ner_tags + rake_tags + semantic_tags\n",
    "\n",
    "# Clean + filter\n",
    "filtered_tags = []\n",
    "seen = set()\n",
    "for tag in raw_tags:\n",
    "    tag_clean = tag.strip().lower()\n",
    "    if tag_clean not in seen and len(tag_clean) > 2 and tag_clean not in {\"developing\", \"collaboration\", \"new\"}:\n",
    "        seen.add(tag_clean)\n",
    "        filtered_tags.append(tag_clean.title())  # Title case for readability\n",
    "\n",
    "# Output\n",
    "print(\"üìå Final Cleaned Auto-Generated Tags:\")\n",
    "for tag in filtered_tags:\n",
    "    print(\"-\", tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Referencing(Multi-doc magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/miniforge3/envs/NCvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "import uuid\n",
    "\n",
    "# ‚úÖ Initialize embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ‚úÖ Initialize ChromaDB with persistent storage\n",
    "chroma_client = chromadb.PersistentClient(path=\"data/chroma_db\")\n",
    "\n",
    "# ‚úÖ Get or create the 'notes' collection\n",
    "collection = chroma_client.get_or_create_collection(name=\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Add new note function\n",
    "def add_note(text, metadata=None):\n",
    "    note_id = str(uuid.uuid4())  # Unique ID\n",
    "    embedding = embedding_model.encode(text)\n",
    "    collection.add(\n",
    "        documents=[text],\n",
    "        embeddings=[embedding],\n",
    "        ids=[note_id],\n",
    "        metadatas=[metadata or {}]\n",
    "    )\n",
    "    return note_id, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Similar notes search\n",
    "def find_similar_notes(query_embedding, current_note_id=None, top_k=3):\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k + 1  # Fetch extra to allow filtering\n",
    "    )\n",
    "    \n",
    "    # Filter out current note\n",
    "    filtered_notes = []\n",
    "    for note_id, doc in zip(results[\"ids\"][0], results[\"documents\"][0]):\n",
    "        if note_id != current_note_id:\n",
    "            filtered_notes.append(doc)\n",
    "        if len(filtered_notes) >= top_k:\n",
    "            break\n",
    "\n",
    "    return filtered_notes\n",
    "\n",
    "\n",
    "# ‚úÖ Example usage\n",
    "new_note = \"GANs generate realistic images.\"\n",
    "note_id, embedding = add_note(new_note, metadata={\"type\": \"note\", \"topic\": \"AI\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_note = \"VAEs also generate images, but their latent space is continuous.\"\n",
    "note_id, embedding = add_note(new_note, metadata={\"type\": \"note\", \"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_note(\"Transformers revolutionized NLP tasks.\", metadata={\"type\": \"note\", \"topic\": \"AI\"}) \n",
    "add_note(\"GANs are useful for data augmentation.\", metadata={\"type\": \"note\", \"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similar Notes:\n",
      "1. GANs generate realistic images.\n",
      "2. GANs are useful for data augmentation.\n",
      "3. Transformers revolutionized NLP tasks.\n"
     ]
    }
   ],
   "source": [
    "similar = find_similar_notes(embedding, current_note_id=note_id)\n",
    "\n",
    "print(\"üîç Similar Notes:\")\n",
    "for i, note in enumerate(similar):\n",
    "    print(f\"{i+1}. {note}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NCvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
